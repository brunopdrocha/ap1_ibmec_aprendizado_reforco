{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83ecb7d3",
   "metadata": {},
   "source": [
    "# Aprendizado por Refor√ßo\n",
    "\n",
    "- Bruno Pil√£o - 202201037911\n",
    "- Mateus Norcia - 202201038381\n",
    "- Isabelle -\n",
    "\n",
    "\n",
    "Este trabalho tem como objetivo aplicar os conceitos fundamentais de Aprendizado por Refor√ßo (Reinforcement Learning) atrav√©s da modelagem de um Processo de Decis√£o de Markov (MDP), utilizando o ambiente Taxi-v3 dispon√≠vel na biblioteca Gymnasium.\n",
    "\n",
    "O ambiente simula um cen√°rio onde um t√°xi deve buscar um passageiro em um ponto espec√≠fico e lev√°-lo at√© o destino correto, dentro de um grid (5x5) com obst√°culos e paredes. O agente (t√°xi) aprende a agir por tentativa e erro, buscando maximizar a recompensa acumulada com base nas a√ß√µes tomadas.\n",
    "\n",
    "![Ambiente Taxi-v3](img/enviroment_taxi.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10d465c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Importando pacotes necessarios compila√ß√£o collab \n",
    "!pip install gymnasium -q\n",
    "!pip install numpy -q\n",
    "!pip install matplotlib -q\n",
    "!pip install pandas -q\n",
    "!pip install seaborn -q\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ba458c",
   "metadata": {},
   "source": [
    "## üß© Defini√ß√£o do Markov Decision Process\n",
    "\n",
    "\n",
    "### Estados (S):\n",
    "- O ambiente tem 500 estados poss√≠veis. Cada estado representa:\n",
    "\n",
    "- Posi√ß√£o do t√°xi (fila, coluna)\n",
    "\n",
    "- Local de origem do passageiro (uma das 5 localiza√ß√µes fixas)\n",
    "\n",
    "    - 0: Vermelho\n",
    "    - 1: Verde\n",
    "    - 2: Amarelo\n",
    "    - 3: Azul\n",
    "    - 4: No taxi\n",
    "\n",
    "### A√ß√µes (A):\n",
    "- 0 = Mover para sul\n",
    "- 1 = Mover para norte\n",
    "- 2 = Mover para leste\n",
    "- 3 = Mover para oeste\n",
    "- 4 = Pegar passageiro\n",
    "- 5 = Deixar passageiro\n",
    "\n",
    "### Transi√ß√µes (P(s'|s,a)):\n",
    "Determin√≠sticas, exceto quando o t√°xi tenta atravessar uma parede ‚Äî nesse caso, ele permanece no mesmo estado.\n",
    "\n",
    "Fun√ß√£o de recompensa (R(s,a)):\n",
    "\n",
    "Cada movimento: ‚àí1\n",
    "\n",
    "A√ß√£o de pegar/deixar incorreta: ‚àí10\n",
    "\n",
    "Passageiro entregue corretamente: +20\n",
    "\n",
    "Fator de desconto (Œ≥):\n",
    "\n",
    "Usaremos Œ≥ = 0.9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
