{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83ecb7d3",
   "metadata": {},
   "source": [
    "# Aprendizado por Refor√ßo\n",
    "\n",
    "- Bruno Pil√£o - 202201037911\n",
    "- Mateus Norcia - 202201038381\n",
    "- Isabelle -\n",
    "\n",
    "\n",
    "Este trabalho tem como objetivo aplicar os conceitos fundamentais de Aprendizado por Refor√ßo (Reinforcement Learning) atrav√©s da modelagem de um Processo de Decis√£o de Markov (MDP), utilizando o ambiente Taxi-v3 dispon√≠vel na biblioteca Gymnasium.\n",
    "\n",
    "O ambiente simula um cen√°rio onde um t√°xi deve buscar um passageiro em um ponto espec√≠fico e lev√°-lo at√© o destino correto, dentro de um grid (5x5) com obst√°culos e paredes. O agente (t√°xi) aprende a agir por tentativa e erro, buscando maximizar a recompensa acumulada com base nas a√ß√µes tomadas.\n",
    "\n",
    "![Ambiente Taxi-v3](img/enviroment_taxi.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ba458c",
   "metadata": {},
   "source": [
    "## üß© Defini√ß√£o do Markov Decision Process\n",
    "\n",
    "\n",
    "### Estados (S):\n",
    "- O ambiente tem 500 estados poss√≠veis. Cada estado representa:\n",
    "- Posi√ß√£o do t√°xi (fila, coluna)\n",
    "- Local de origem do passageiro (uma das 5 localiza√ß√µes fixas)\n",
    "    - 0: Vermelho\n",
    "    - 1: Verde\n",
    "    - 2: Amarelo\n",
    "    - 3: Azul\n",
    "    - 4: No taxi\n",
    "\n",
    "### A√ß√µes (A):\n",
    "- 0 = Mover para sul\n",
    "- 1 = Mover para norte\n",
    "- 2 = Mover para leste\n",
    "- 3 = Mover para oeste\n",
    "- 4 = Pegar passageiro\n",
    "- 5 = Deixar passageiro\n",
    "\n",
    "### Recompensas\n",
    "- R(s, a) = ‚àí1 por passo.\n",
    "- Estados (0,1);(0,4);(4,1);(3,4) s√£o terminais com recompensa +20 (depedendo da Localiza√ß√£o do Hotel).\n",
    "- Estado tem recompensa negativa ‚àí10, por executar indevidamente as a√ß√µes de embarque e desembarque.\n",
    "### Transi√ß√µes (P(s'|s,a)):\n",
    "Determin√≠sticas, exceto quando o t√°xi tenta atravessar uma parede, nesse caso, ele permanece no mesmo estado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c923bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Importando pacotes necessarios compila√ß√£o collab\n",
    "! pip install gymnasium numpy matplotlib pandas seaborn tqdm pygame -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f553826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "75c4db03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o ambiente Taxi-v3\n",
    "env_default = gym.make(\"Taxi-v3\")\n",
    "env_raining = gym.make(\"Taxi-v3\",is_rainy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b7b8b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo estados do ambiente\n",
    "estados=[\n",
    " (0, 0), (0, 1), (0, 2), (0, 3), (0, 4),\n",
    " (1, 0), (1, 1), (1, 2), (1, 3), (1, 4),\n",
    " (2, 0), (2, 1), (2, 2), (2, 3), (2, 4),\n",
    " (3, 0), (3, 1), (3, 2), (3, 3), (3, 4),\n",
    " (4, 0), (4, 1), (4, 2), (4, 3), (4, 4)\n",
    "]\n",
    "\n",
    "#Definindo a√ß√µes do ambiente\n",
    "acoes = {\n",
    "    0: \"South ‚¨áÔ∏è\",\n",
    "    1: \"North ‚¨ÜÔ∏è\",\n",
    "    2: \"East ‚û°Ô∏è\",\n",
    "    3: \"West ‚¨ÖÔ∏è\",\n",
    "    4: \"Pickup üöñ\",\n",
    "    5: \"Dropoff üõë\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c591aaea",
   "metadata": {},
   "source": [
    "## Equa√ß√£o de Belman\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ec44bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(6), np.int64(500))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_default.action_space.n, env_default.observation_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bb0ba68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A√ß√£o 0:\n",
      " ‚Üí Pr√≥ximo estado: 180, Recompensa: -1, Terminal: False (Probabilidade: 1.0)\n",
      "A√ß√£o 1:\n",
      " ‚Üí Pr√≥ximo estado: 80, Recompensa: -1, Terminal: False (Probabilidade: 1.0)\n",
      "A√ß√£o 2:\n",
      " ‚Üí Pr√≥ximo estado: 80, Recompensa: -1, Terminal: False (Probabilidade: 1.0)\n",
      "A√ß√£o 3:\n",
      " ‚Üí Pr√≥ximo estado: 60, Recompensa: -1, Terminal: False (Probabilidade: 1.0)\n",
      "A√ß√£o 4:\n",
      " ‚Üí Pr√≥ximo estado: 80, Recompensa: -10, Terminal: False (Probabilidade: 1.0)\n",
      "A√ß√£o 5:\n",
      " ‚Üí Pr√≥ximo estado: 80, Recompensa: -10, Terminal: False (Probabilidade: 1.0)\n"
     ]
    }
   ],
   "source": [
    "state = 80\n",
    "for action in range(env_default.action_space.n):\n",
    "    transitions = env_default.unwrapped.P[state][action]\n",
    "    print(f\"A√ß√£o {action}:\")\n",
    "    for prob, next_state, reward, done in transitions:\n",
    "        print(f\" ‚Üí Pr√≥ximo estado: {next_state}, Recompensa: {reward}, Terminal: {done} (Probabilidade: {prob})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68619e2a",
   "metadata": {},
   "source": [
    "## Recompensas\n",
    "\n",
    "- -1 per step unless other reward is triggered.\n",
    "\n",
    "- +20 delivering passenger.\n",
    "\n",
    "- -10 executing ‚Äúpickup‚Äù and ‚Äúdrop-off‚Äù actions illegally."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
